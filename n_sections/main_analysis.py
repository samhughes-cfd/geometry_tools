# n_sections/main_analysis.py

import sys
from pathlib import Path
from datetime import datetime  # â±ï¸ Added for timestamping

# â”€â”€â”€â”€â”€ Add project root to sys.path BEFORE any project imports â”€â”€â”€â”€â”€
CURRENT_FILE = Path(__file__).resolve()
PROJECT_ROOT = CURRENT_FILE.parents[1]  # This points to geometry_tools
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

# â”€â”€â”€â”€â”€ Now do the rest of your imports â”€â”€â”€â”€â”€
import csv
import logging
import numpy as np

from analysis.process_section_analysis import ProcessSectionAnalysis


# â”€â”€â”€â”€â”€ Main function to run the analysis pipeline â”€â”€â”€â”€â”€
def main():
    # â”€â”€â”€â”€â”€ Setup directories â”€â”€â”€â”€â”€
    BASE_DIR = PROJECT_ROOT / "n_sections"
    BLADE_DIR = BASE_DIR / "blade"

    # â±ï¸ Timestamp for this run
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

    # Timestamped subdirectories
    RESULTS = BASE_DIR / "results/analysis" / timestamp
    LOGS = BASE_DIR / "logs/analysis" / timestamp

    for d in (RESULTS, LOGS):
        d.mkdir(parents=True, exist_ok=True)

    # â”€â”€â”€â”€â”€ Logging setup â”€â”€â”€â”€â”€
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(LOGS / "main.log", mode="w", encoding="utf-8"),
            logging.StreamHandler(),
        ],
    )
    logging.info("ğŸŒ€ DXF mesh-convergence pipeline started")
    logging.info("â± Timestamped output directory: %s", timestamp)

    # â”€â”€â”€â”€â”€ Load blade station metadata â”€â”€â”€â”€â”€
    stations_csv = BLADE_DIR / "blade_stations.csv"
    stations = []

    with open(stations_csv, newline="") as f:
        reader = csv.DictReader(f)
        for row in reader:
            r_over_R = float(row["r/R [-]"])
            Cx = float(row["Cx [mm]"]) / 1000
            Cy = float(row["Cy [mm]"]) / 1000
            r = float(row["Cz [mm]"]) / 1000
            B_r = float(row["B [deg]"])
            filename = row["filename"]
            dxf = BLADE_DIR / filename
            label = Path(filename).stem
            stations.append((dxf, label, r, r_over_R, B_r, Cx, Cy))

    # â”€â”€â”€â”€â”€ Load material definitions â”€â”€â”€â”€â”€
    materials_csv = BLADE_DIR / "materials.csv"
    material_dict = {}

    with open(materials_csv, newline="") as f:
        reader = csv.DictReader(f)
        for row in reader:
            filename = row["filename"].lower()
            material_dict[filename] = {
                "name": row["material_name"],
                "E": float(row["elastic_modulus"]),
                "nu": float(row["poissons_ratio"]),
                "fy": float(row["yield_strength"]),
                "rho": float(row["density"]),
                "color": row["color"],
            }

    # â”€â”€â”€â”€â”€ Mesh convergence parameters â”€â”€â”€â”€â”€
    N = 3                         # Number of mesh refinement levels
    h0 = 40.0                     # Base element area (coarsest) in mmÂ²
    hs = h0 / (4 ** np.arange(N))  # e.g., [40, 10, 2.5, ...]
    logging.info("Mesh size targets: %s", hs)

    # â”€â”€â”€â”€â”€ Process each blade station â”€â”€â”€â”€â”€
    for dxf, label, r, r_over_R, B_r, Cx, Cy in stations:
        material = material_dict.get(dxf.name.lower())
        if material is None:
            logging.error(f"No material found for DXF file: {dxf.name}")
            continue

        section = ProcessSectionAnalysis(
            dxf=dxf,
            label=label,
            r=r,
            r_over_R=r_over_R,
            B_r=B_r,
            Cx=Cx,
            Cy=Cy,
            material=material,  # <-- Now includes "name" key
            hs=hs,
            results_dir=RESULTS,
            logs_dir=LOGS,
        )
        section.run()

    logging.info("âœ… SECTION ANALYSIS pipeline complete â€” results saved in: %s", RESULTS)


# â”€â”€â”€â”€â”€ Entry Point â”€â”€â”€â”€â”€
if __name__ == "__main__":
    main()